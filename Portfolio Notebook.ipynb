{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32667893",
   "metadata": {},
   "source": [
    "# Machine Learning Projects Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473fb118",
   "metadata": {},
   "source": [
    "This repository contains three machine learning projects created for AI Model Share Competitions. These projects were created for Advanced Projects in Machine Learning, a Quantitative Methods in the Social Sciences course at Columbia University."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11b3abc",
   "metadata": {},
   "source": [
    "## Project 1 - World Happiness Classification, Tabular Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b367a1",
   "metadata": {},
   "source": [
    "[project notebook](https://github.com/AmeliaSys/Machine-Learning-Projects/blob/main/World%20Happiness%20Classification/Assignment_1.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399a3093",
   "metadata": {},
   "source": [
    "This project used tabular data to predict a country's happiness level from one of 5 categories (very high, high, average, low, very low). The dataset consisted of 7 numerical features and dummy variables for the region and sub-region of each country. \n",
    "\n",
    "Using the Random Forest SFM method, feature importances of each variable were exracted to determine the most important features in the dataset. The numerical features have higher feature importance than region / sub-region. GDP per capita is the variable with the highest feature importance, followed by healthy life expectancy.\n",
    "\n",
    "The models experimented with were:\n",
    "1. Support Vector Machines\n",
    "2. Random Forest Classifier\n",
    "3. Logistic Regression\n",
    "4. Gradient Boosting Trees\n",
    "\n",
    "Logistic Regression, Random Forest, and Support Vector Machine models tuned with GridSearchCV performed very similarly when evaluated on stratified k-fold, with an accuracy score ~0.89. A basic SVC model generalized the strongest on the test data, with a f1-score of 0.499.\n",
    "\n",
    "The top models on the leaderboard reached an f1-score of 0.64 and used Sequential approaches, a model type which I did not experiment with. A Random Forest model also reached a f1-score of 0.58, which is substantially higher than the results of my architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e314895",
   "metadata": {},
   "source": [
    "## Project 2 - Xray Classification, Image Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac45451",
   "metadata": {},
   "source": [
    "[project notebook](https://github.com/AmeliaSys/Machine-Learning-Projects/blob/main/Xray%20Classification/Assignment_2.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef080ee4",
   "metadata": {},
   "source": [
    "This project uses chest xray image data of healthy patients, patients with COVID-19, and patients with pneunomia to create classification models. The dataset consists of 4032 images split across three categories (1344 in each).\n",
    "\n",
    "The types of models experimented with were:\n",
    "1. Simple Convolutional Neural Networks (CNNs)\n",
    "2. CNN with Fire Modules\n",
    "3. VGG16 Transfer Learning\n",
    "4. CNN with CONV1D layers\n",
    "5. CNN with L1 and L2 Regularization\n",
    "\n",
    "We also experimented with augmented data, altering rotation, zoom, width shift and height shift parameters.\n",
    "\n",
    "The top performing model was a four layer CNN with Conv1D layers and l1 and l2 regularization, with ReLU activation and SGD optimization. My models placed around 100th in rank. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1e8715",
   "metadata": {},
   "source": [
    "## Project 3 - IMDB Sentiment Analysis, Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c718a2",
   "metadata": {},
   "source": [
    "[project_notebook](https://github.com/AmeliaSys/Machine-Learning-Projects/blob/main/IMDB%20Sentiment%20Analysis/Assignment_3.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acc91f2",
   "metadata": {},
   "source": [
    "The third project uses text data from 6900 IMDB movie reviews to predict two sentiment classifications, positive or negative. \n",
    "\n",
    "In the models built, the following techniques / modeling approaches are experimented with:\n",
    "1. LSTM cells\n",
    "2. Embedding layers\n",
    "3. Conv1D layers\n",
    "4. Transfer learning with glove embeddings\n",
    "5. Bidirectional LSTM\n",
    "6. Maximum length of text used\n",
    "\n",
    "A more complex approach of 3 LSTM and embedding layers with dropout produced the strongest results, with a f1-score on the test data of 0.81. My top performing model is ranked #17 on the leaderboard. The top performing models reached an f1-score of 0.83, with even more complex architectures. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
