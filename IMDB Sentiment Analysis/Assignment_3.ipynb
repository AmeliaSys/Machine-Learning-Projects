{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ct8eF_R9USuw",
        "CaiyEArYUVAc",
        "U4_WWffeUZeN",
        "4SIGJTy4UcdS",
        "uR-aHmLnZuTV",
        "ZdQaJM_xRGzi",
        "SBYPAmqxUtW9"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Amelia Sayes\n",
        "\n",
        "ams2638\n",
        "\n",
        "Adv ML Assignment #3"
      ],
      "metadata": {
        "id": "aelomNegUz35"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##File Setup"
      ],
      "metadata": {
        "id": "NGlFZtiuU6Zu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLTIaMB3ChSW"
      },
      "outputs": [],
      "source": [
        "#install aimodelshare library\n",
        "! pip install aimodelshare==0.0.189"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3PiJXBhC5y-"
      },
      "outputs": [],
      "source": [
        "# Get competition data\n",
        "from aimodelshare import download_data\n",
        "download_data('public.ecr.aws/y2e2a1d6/sst2_competition_data-repository:latest') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jT0qFCZFNzHq",
        "outputId": "e60f9cab-a8a1-480d-f924-172f60e0b547"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    The Rock is destined to be the 21st Century 's...\n",
              "1    The gorgeously elaborate continuation of `` Th...\n",
              "2    Singer/composer Bryan Adams contributes a slew...\n",
              "3                 Yet the act is still charming here .\n",
              "4    Whether or not you 're enlightened by any of D...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Set up X_train, X_test, and y_train_labels objects\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=Warning)\n",
        "\n",
        "X_train=pd.read_csv(\"sst2_competition_data/X_train.csv\", squeeze=True)\n",
        "X_test=pd.read_csv(\"sst2_competition_data/X_test.csv\", squeeze=True)\n",
        "\n",
        "y_train_labels=pd.read_csv(\"sst2_competition_data/y_train_labels.csv\", squeeze=True)\n",
        "\n",
        "# ohe encode Y data\n",
        "y_train = pd.get_dummies(y_train_labels)\n",
        "\n",
        "X_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEzPoXPj3V7u"
      },
      "source": [
        "###2.   Preprocess data using keras tokenizer / Write and Save Preprocessor function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16QV9Y9TC3B3",
        "outputId": "ebe37a03-9af8-46ed-d8f2-db5e83406709"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6920, 40)\n",
            "(1821, 40)\n"
          ]
        }
      ],
      "source": [
        "# This preprocessor function makes use of the tf.keras tokenizer\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "# Build vocabulary from training text data\n",
        "tokenizer = Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "# preprocessor tokenizes words and makes sure all documents have the same length\n",
        "def preprocessor(data, maxlen=40, max_words=10000):\n",
        "\n",
        "    sequences = tokenizer.texts_to_sequences(data)\n",
        "\n",
        "    word_index = tokenizer.word_index\n",
        "    X = pad_sequences(sequences, maxlen=maxlen)\n",
        "\n",
        "    return X\n",
        "\n",
        "print(preprocessor(X_train).shape)\n",
        "print(preprocessor(X_test).shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import aimodelshare as ai\n",
        "ai.export_preprocessor(preprocessor,\"\") "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XPdswM4VSwd",
        "outputId": "5dfecf3d-39aa-4883-89b9-a28cd3eeec94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your preprocessor is now saved to 'preprocessor.zip'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtgkM02MDpkO",
        "outputId": "78c38d8b-0af9-45af-819e-5230ac13c80a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI Modelshare Username:··········\n",
            "AI Modelshare Password:··········\n",
            "AI Model Share login credentials set successfully.\n"
          ]
        }
      ],
      "source": [
        "#Set credentials using modelshare.org username/password\n",
        "\n",
        "from aimodelshare.aws import set_credentials\n",
        "    \n",
        "apiurl=\"https://rlxjxnoql9.execute-api.us-east-1.amazonaws.com/prod/m\" #This is the unique rest api that powers this specific Playground\n",
        "\n",
        "set_credentials(apiurl=apiurl)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Discuss the dataset in general terms and describe why building a predictive model using this data might be practically useful.  Who could benefit from a model like this? Explain.\n"
      ],
      "metadata": {
        "id": "ct8eF_R9USuw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset consists of X data which are movie reviews and y data which is a label of the review either being positive or negative. The goal of this predictive model is to classify movie reviews correctly as either positive or negative. \n",
        "\n",
        "A predictive model able to classify sentiment of text is helpful in a number of ways. E.g. To calculate average sentiment across reviews for a movie. Platforms like IMDB and Rotten Tomatoes can use this information to produce a rating of movies. Not only is this helpful for the company, this is helpful to people who want to know how good a movie is."
      ],
      "metadata": {
        "id": "HTHjAdo-jzjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnmHxz30SiqZ",
        "outputId": "9f0a0e93-8124-42d6-ecfe-6d709da6deab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       The Rock is destined to be the 21st Century 's...\n",
              "1       The gorgeously elaborate continuation of `` Th...\n",
              "2       Singer/composer Bryan Adams contributes a slew...\n",
              "3                    Yet the act is still charming here .\n",
              "4       Whether or not you 're enlightened by any of D...\n",
              "                              ...                        \n",
              "6915                                      A real snooze .\n",
              "6916                                       No surprises .\n",
              "6917    We 've seen the hippie-turned-yuppie plot befo...\n",
              "6918    Her fans walked out muttering words like `` ho...\n",
              "6919                                  In this case zero .\n",
              "Name: text, Length: 6920, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "SxTLvrr4SOIb",
        "outputId": "d0e3d5f6-102e-4b0d-e299-830a21f338c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Negative  Positive\n",
              "0            0         1\n",
              "1            0         1\n",
              "2            0         1\n",
              "3            0         1\n",
              "4            0         1\n",
              "...        ...       ...\n",
              "6915         1         0\n",
              "6916         1         0\n",
              "6917         0         1\n",
              "6918         1         0\n",
              "6919         1         0\n",
              "\n",
              "[6920 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0823124f-2041-45df-871c-c72e6a09e255\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Negative</th>\n",
              "      <th>Positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6915</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6916</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6917</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6918</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6919</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6920 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0823124f-2041-45df-871c-c72e6a09e255')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0823124f-2041-45df-871c-c72e6a09e255 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0823124f-2041-45df-871c-c72e6a09e255');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Run at least three prediction models to try to predict the SST sentiment dataset well.\n"
      ],
      "metadata": {
        "id": "CaiyEArYUVAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 40"
      ],
      "metadata": {
        "id": "wKaexS7LW8OS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.a. Use Embedding layers and LSTM layers in at least one model\n"
      ],
      "metadata": {
        "id": "U4_WWffeUZeN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model #60"
      ],
      "metadata": {
        "id": "u5fbqimXWEY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Flatten\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(Embedding(10000, 16, input_length=max_len))\n",
        "model2.add(LSTM(100, return_sequences=True, dropout=0.2))\n",
        "model2.add(LSTM(100, dropout=0.3))\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEpo6_miYBMn",
        "outputId": "99beabe0-3c8b-42ab-e1bc-1e6bd7256ba4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_6 (Embedding)     (None, 40, 16)            160000    \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 40, 100)           46800     \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 100)               80400     \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 2)                 202       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 287,402\n",
            "Trainable params: 287,402\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "history = model2.fit(preprocessor(X_train), y_train,\n",
        "                    epochs=5,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyF0u5S7UV32",
        "outputId": "fc8c6401-e6c3-4a94-fcc5-2c2b4af4587a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "173/173 [==============================] - 21s 104ms/step - loss: 0.6593 - acc: 0.6275 - val_loss: 0.7635 - val_acc: 0.4191\n",
            "Epoch 2/5\n",
            "173/173 [==============================] - 17s 97ms/step - loss: 0.4811 - acc: 0.7731 - val_loss: 0.6508 - val_acc: 0.6922\n",
            "Epoch 3/5\n",
            "173/173 [==============================] - 15s 90ms/step - loss: 0.3638 - acc: 0.8447 - val_loss: 0.5762 - val_acc: 0.7095\n",
            "Epoch 4/5\n",
            "173/173 [==============================] - 15s 89ms/step - loss: 0.2996 - acc: 0.8737 - val_loss: 0.6502 - val_acc: 0.7038\n",
            "Epoch 5/5\n",
            "173/173 [==============================] - 16s 95ms/step - loss: 0.2523 - acc: 0.8990 - val_loss: 0.5360 - val_acc: 0.7601\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = mycompetition.get_leaderboard()\n",
        "compar = data[[\"version\", \"accuracy\", \"f1_score\", \"precision\", \"recall\", \"model_type\"]]\n",
        "print(compar[compar[\"version\"].isin([60])])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVLW7W5pV-zw",
        "outputId": "cc71a020-b7fc-47ed-a9b6-5c6cf90cf8ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   version  accuracy  f1_score  precision    recall  model_type\n",
            "6       60  0.792536  0.792094   0.795156  0.792587  Sequential\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.b. Use Embedding layers and Conv1d layers in at least one model\n"
      ],
      "metadata": {
        "id": "4SIGJTy4UcdS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 61"
      ],
      "metadata": {
        "id": "uR-aHmLnZuTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.layers import SimpleRNN, LSTM,Embedding\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(10000, 8, input_length=max_len))\n",
        "model.add(layers.Conv1D(50, 7, activation='relu')) \n",
        "model.add(layers.GlobalMaxPooling1D())\n",
        "model.add(layers.Dense(2, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCFcaMr5W4D_",
        "outputId": "415e0670-7939-4a9a-fef7-2aef082417cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_10 (Embedding)    (None, 40, 8)             80000     \n",
            "                                                                 \n",
            " conv1d_9 (Conv1D)           (None, 34, 50)            2850      \n",
            "                                                                 \n",
            " global_max_pooling1d_3 (Glo  (None, 50)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 2)                 102       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 82,952\n",
            "Trainable params: 82,952\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "history = model.fit(preprocessor(X_train), y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63c8mxtaYQ0O",
        "outputId": "124b004f-b91c-441c-f4cc-0480383855f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "173/173 [==============================] - 2s 6ms/step - loss: 0.6652 - acc: 0.6149 - val_loss: 0.8895 - val_acc: 0.1488\n",
            "Epoch 2/10\n",
            "173/173 [==============================] - 1s 6ms/step - loss: 0.6280 - acc: 0.6239 - val_loss: 0.8109 - val_acc: 0.3266\n",
            "Epoch 3/10\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 0.5188 - acc: 0.7520 - val_loss: 0.7587 - val_acc: 0.5499\n",
            "Epoch 4/10\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 0.4034 - acc: 0.8331 - val_loss: 0.5764 - val_acc: 0.7298\n",
            "Epoch 5/10\n",
            "173/173 [==============================] - 1s 6ms/step - loss: 0.3286 - acc: 0.8680 - val_loss: 0.5973 - val_acc: 0.7153\n",
            "Epoch 6/10\n",
            "173/173 [==============================] - 1s 6ms/step - loss: 0.2804 - acc: 0.8864 - val_loss: 0.5877 - val_acc: 0.7298\n",
            "Epoch 7/10\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 0.2423 - acc: 0.9005 - val_loss: 0.6672 - val_acc: 0.6879\n",
            "Epoch 8/10\n",
            "173/173 [==============================] - 1s 6ms/step - loss: 0.2138 - acc: 0.9146 - val_loss: 0.5740 - val_acc: 0.7572\n",
            "Epoch 9/10\n",
            "173/173 [==============================] - 1s 6ms/step - loss: 0.1915 - acc: 0.9230 - val_loss: 0.6872 - val_acc: 0.7153\n",
            "Epoch 10/10\n",
            "173/173 [==============================] - 1s 8ms/step - loss: 0.1709 - acc: 0.9317 - val_loss: 0.6869 - val_acc: 0.7290\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = mycompetition.get_leaderboard()\n",
        "compar = data[[\"version\", \"accuracy\", \"f1_score\", \"precision\", \"recall\", \"model_type\"]]\n",
        "print(compar[compar[\"version\"].isin([60, 61])])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4No3LVyZwWU",
        "outputId": "55b03c2d-3412-4dbe-e62e-9659ffe1180c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   version  accuracy  f1_score  precision    recall  model_type\n",
            "6       60  0.792536  0.792094   0.795156  0.792587  Sequential\n",
            "7       61  0.788145  0.786414   0.798021  0.788245  Sequential\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.c. Use transfer learning with glove embeddings for at least one of these models\n"
      ],
      "metadata": {
        "id": "n-z865j4UekS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model #84"
      ],
      "metadata": {
        "id": "ZdQaJM_xRGzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# change max len to be 100 to be compatible with glove\n",
        "def preprocessor(data, maxlen=50, max_words=10000):\n",
        "\n",
        "    sequences = tokenizer.texts_to_sequences(data)\n",
        "\n",
        "    word_index = tokenizer.word_index\n",
        "    X = pad_sequences(sequences, maxlen=maxlen)\n",
        "\n",
        "    return X\n",
        "\n",
        "print(preprocessor(X_train).shape)\n",
        "print(preprocessor(X_test).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRs4gI3iEC4N",
        "outputId": "5c34b0d2-3f8a-407b-bcbf-ea1a058d764b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6920, 50)\n",
            "(1821, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! wget http://nlp.stanford.edu/data/wordvecs/glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1v5_LWGg56r",
        "outputId": "3d306a00-3259-4243-a8e2-240e7ed57ca8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-13 14:47:34--  http://nlp.stanford.edu/data/wordvecs/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/wordvecs/glove.6B.zip [following]\n",
            "--2023-04-13 14:47:34--  https://nlp.stanford.edu/data/wordvecs/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/wordvecs/glove.6B.zip [following]\n",
            "--2023-04-13 14:47:34--  https://downloads.cs.stanford.edu/nlp/data/wordvecs/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182753 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip.1’\n",
            "\n",
            "glove.6B.zip.1      100%[===================>] 822.24M  5.01MB/s    in 2m 39s  \n",
            "\n",
            "2023-04-13 14:50:13 (5.17 MB/s) - ‘glove.6B.zip.1’ saved [862182753/862182753]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip glove.6B.zip "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjBI75pNhQIm",
        "outputId": "680beb69-ff36-4365-965f-904a49abb38e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n",
            "  inflating: glove.6B.50d.txt        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract embedding data for 100 feature embedding matrix\n",
        "import os\n",
        "glove_dir = os.getcwd()\n",
        "\n",
        "embeddings_index = {}\n",
        "f = open(os.path.join(glove_dir, 'glove.6B.50d.txt'))\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVML8cfghS9H",
        "outputId": "f2c00b7a-75f7-443c-ff47-616fe3a3edb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400001 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 50 # change if you use txt files using larger number of features\n",
        "max_words = 10000\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if i < max_words:\n",
        "        if embedding_vector is not None:\n",
        "            # Words not found in embedding index will be all-zeros.\n",
        "            embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "fMWXgIckhWe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "max_len = 50\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Embedding(max_words, embedding_dim, input_length=max_len)) \n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(50, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(50, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GtVAitMi1v2",
        "outputId": "037fd5f7-20a2-4ee1-a5b0-75e491eb67d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_12 (Embedding)    (None, 50, 50)            500000    \n",
            "                                                                 \n",
            " flatten_12 (Flatten)        (None, 2500)              0         \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 50)                125050    \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 50)                2550      \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 2)                 102       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 627,702\n",
            "Trainable params: 627,702\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.layers[0].set_weights([embedding_matrix])\n",
        "model.layers[0].trainable = False"
      ],
      "metadata": {
        "id": "0fTnPFoWIH8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNhrUSYHOlUG",
        "outputId": "e6dd85d7-7b4f-4574-8e7f-dd8a47a6ad3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_12 (Embedding)    (None, 50, 50)            500000    \n",
            "                                                                 \n",
            " flatten_12 (Flatten)        (None, 2500)              0         \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 50)                125050    \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 50)                2550      \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 2)                 102       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 627,702\n",
            "Trainable params: 127,702\n",
            "Non-trainable params: 500,000\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.experimental.RMSprop(learning_rate = 0.0001), loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "history = model.fit(preprocessor(X_train), y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zbq0G5MNjBLO",
        "outputId": "6ad0ab80-23eb-4107-c243-4181dcd9328c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "173/173 [==============================] - 3s 10ms/step - loss: 0.6689 - acc: 0.6109 - val_loss: 0.8645 - val_acc: 0.1510\n",
            "Epoch 2/20\n",
            "173/173 [==============================] - 2s 10ms/step - loss: 0.6356 - acc: 0.6201 - val_loss: 0.8439 - val_acc: 0.1929\n",
            "Epoch 3/20\n",
            "173/173 [==============================] - 2s 11ms/step - loss: 0.6045 - acc: 0.6530 - val_loss: 0.8519 - val_acc: 0.2818\n",
            "Epoch 4/20\n",
            "173/173 [==============================] - 1s 8ms/step - loss: 0.5755 - acc: 0.6895 - val_loss: 0.8204 - val_acc: 0.3996\n",
            "Epoch 5/20\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 0.5471 - acc: 0.7188 - val_loss: 0.8010 - val_acc: 0.4783\n",
            "Epoch 6/20\n",
            "173/173 [==============================] - 1s 6ms/step - loss: 0.5206 - acc: 0.7444 - val_loss: 0.7489 - val_acc: 0.5621\n",
            "Epoch 7/20\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 0.4968 - acc: 0.7619 - val_loss: 0.7064 - val_acc: 0.6199\n",
            "Epoch 8/20\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 0.4750 - acc: 0.7782 - val_loss: 0.7397 - val_acc: 0.6033\n",
            "Epoch 9/20\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 0.4541 - acc: 0.7944 - val_loss: 0.7595 - val_acc: 0.6069\n",
            "Epoch 10/20\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 0.4334 - acc: 0.8047 - val_loss: 0.7394 - val_acc: 0.6301\n",
            "Epoch 11/20\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 0.4143 - acc: 0.8168 - val_loss: 0.7287 - val_acc: 0.6380\n",
            "Epoch 12/20\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 0.3964 - acc: 0.8280 - val_loss: 0.7357 - val_acc: 0.6402\n",
            "Epoch 13/20\n",
            "173/173 [==============================] - 1s 6ms/step - loss: 0.3787 - acc: 0.8354 - val_loss: 0.8752 - val_acc: 0.5780\n",
            "Epoch 14/20\n",
            "173/173 [==============================] - 1s 6ms/step - loss: 0.3618 - acc: 0.8508 - val_loss: 0.8500 - val_acc: 0.5968\n",
            "Epoch 15/20\n",
            "173/173 [==============================] - 1s 6ms/step - loss: 0.3443 - acc: 0.8620 - val_loss: 0.7603 - val_acc: 0.6402\n",
            "Epoch 16/20\n",
            "173/173 [==============================] - 1s 8ms/step - loss: 0.3270 - acc: 0.8672 - val_loss: 0.7719 - val_acc: 0.6488\n",
            "Epoch 17/20\n",
            "173/173 [==============================] - 2s 10ms/step - loss: 0.3098 - acc: 0.8799 - val_loss: 0.8165 - val_acc: 0.6337\n",
            "Epoch 18/20\n",
            "173/173 [==============================] - 2s 9ms/step - loss: 0.2930 - acc: 0.8887 - val_loss: 0.8630 - val_acc: 0.6228\n",
            "Epoch 19/20\n",
            "173/173 [==============================] - 1s 8ms/step - loss: 0.2760 - acc: 0.8970 - val_loss: 0.8942 - val_acc: 0.6221\n",
            "Epoch 20/20\n",
            "173/173 [==============================] - 2s 9ms/step - loss: 0.2590 - acc: 0.9059 - val_loss: 0.8960 - val_acc: 0.6185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = mycompetition.get_leaderboard()\n",
        "compar = data[[\"version\", \"accuracy\", \"f1_score\", \"precision\", \"recall\", \"model_type\"]]\n",
        "print(compar[compar[\"version\"].isin([60, 61, 84])].sort_values(\"f1_score\", ascending = False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xbgtl_ZGRKYD",
        "outputId": "21d61392-febf-4c60-9aa6-eb634a4d0267"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    version  accuracy  f1_score  precision    recall  model_type\n",
            "11       60  0.792536  0.792094   0.795156  0.792587  Sequential\n",
            "12       61  0.788145  0.786414   0.798021  0.788245  Sequential\n",
            "56       84  0.678375  0.675876   0.684226  0.678473  Sequential\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Discuss which models performed better and point out relevant hyper-parameter values for successful models.\n",
        "Submit your best three models to the leader board for the SST Model Share competition."
      ],
      "metadata": {
        "id": "EFHiejrHUhK5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = mycompetition.get_leaderboard()\n",
        "compar = data[[\"version\", \"accuracy\", \"f1_score\", \"precision\", \"recall\", \"model_type\"]]\n",
        "print(compar[compar[\"version\"].isin([60, 61, 84])].sort_values(\"f1_score\", ascending = False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXJyKLs-Rdja",
        "outputId": "8d58ed75-3715-4ac8-93f0-9135da614724"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    version  accuracy  f1_score  precision    recall  model_type\n",
            "11       60  0.792536  0.792094   0.795156  0.792587  Sequential\n",
            "12       61  0.788145  0.786414   0.798021  0.788245  Sequential\n",
            "56       84  0.678375  0.675876   0.684226  0.678473  Sequential\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The highest performing model, #60 is my first model which consists of 1 embedding layer with 10,000 input dimensions and 16 output dimensions, and 2 LSTM layers, each with 100 neurons. The first LSTM layer has a dropout rate of 0.2 and the secon has a dropout rate of 0.3. The model is flattened before the dense layer.This layer used the provided preprocessing technique that limits reviews to 40 words only. After training for 5 epochs in batches of 32, it rendered a f1_score of 0.792.\n",
        "\n",
        "This is only slightly higher than model #61, which uses 1 Embedding layer with 10000 input dimensions and 8 output dimensions and 1 Conv1D layer with 50 filters and a kernel size of 7. The Conv1D layer is activated by relu and is followed by Global MaxPooling 1D. This is a more simple model compared to #60. The f1_score on the test data is 0.786.\n",
        "\n",
        "The weakest model was #84 which uses transfer learning with glove embeddings. Even though this is a more compelx model, the results are significantly weaker than the other models with an f1-score of only 0.676."
      ],
      "metadata": {
        "id": "hYBENFF9R0fs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Fit and submit up to three more models after learning from your team.\n"
      ],
      "metadata": {
        "id": "GVvK64GkUlys"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.a. Model #85\n",
        "LSTM and Embedding model with more layers to improve on Model #60"
      ],
      "metadata": {
        "id": "Ig7zSzHeUqop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Flatten\n",
        "max_len = 40\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(10000, 16, input_length=max_len))\n",
        "model.add(LSTM(50, return_sequences=True, dropout=0.2))\n",
        "model.add(LSTM(50, return_sequences=True, dropout=0.2))\n",
        "model.add(LSTM(80, dropout=0.3))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5753329e-0999-4b8a-9b0e-1e157413139d",
        "id": "LsWxJEXFUx49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_16 (Embedding)    (None, 40, 16)            160000    \n",
            "                                                                 \n",
            " lstm_25 (LSTM)              (None, 40, 50)            13400     \n",
            "                                                                 \n",
            " lstm_26 (LSTM)              (None, 40, 50)            20200     \n",
            "                                                                 \n",
            " lstm_27 (LSTM)              (None, 80)                41920     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 80)                0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 2)                 162       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 235,682\n",
            "Trainable params: 235,682\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "history = model.fit(preprocessor(X_train), y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea80492e-c57c-4c29-f3c4-7cf0714fcf70",
        "id": "PSqiHjXIUx4-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "173/173 [==============================] - 28s 117ms/step - loss: 0.6535 - acc: 0.6293 - val_loss: 0.7233 - val_acc: 0.4986\n",
            "Epoch 2/10\n",
            "173/173 [==============================] - 19s 112ms/step - loss: 0.4876 - acc: 0.7679 - val_loss: 0.5359 - val_acc: 0.7522\n",
            "Epoch 3/10\n",
            "173/173 [==============================] - 15s 84ms/step - loss: 0.3767 - acc: 0.8277 - val_loss: 0.7775 - val_acc: 0.6156\n",
            "Epoch 4/10\n",
            "173/173 [==============================] - 16s 91ms/step - loss: 0.3078 - acc: 0.8663 - val_loss: 0.5354 - val_acc: 0.7616\n",
            "Epoch 5/10\n",
            "173/173 [==============================] - 16s 93ms/step - loss: 0.2601 - acc: 0.8911 - val_loss: 0.4058 - val_acc: 0.8338\n",
            "Epoch 6/10\n",
            "173/173 [==============================] - 15s 87ms/step - loss: 0.2162 - acc: 0.9061 - val_loss: 0.6450 - val_acc: 0.7594\n",
            "Epoch 7/10\n",
            "173/173 [==============================] - 14s 84ms/step - loss: 0.1907 - acc: 0.9216 - val_loss: 0.5208 - val_acc: 0.8100\n",
            "Epoch 8/10\n",
            "173/173 [==============================] - 15s 87ms/step - loss: 0.1753 - acc: 0.9296 - val_loss: 0.7813 - val_acc: 0.7225\n",
            "Epoch 9/10\n",
            "173/173 [==============================] - 16s 94ms/step - loss: 0.1516 - acc: 0.9371 - val_loss: 0.7751 - val_acc: 0.7160\n",
            "Epoch 10/10\n",
            "173/173 [==============================] - 16s 93ms/step - loss: 0.1435 - acc: 0.9418 - val_loss: 0.6355 - val_acc: 0.7818\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = mycompetition.get_leaderboard()\n",
        "compar = data[[\"version\", \"accuracy\", \"f1_score\", \"precision\", \"recall\", \"model_type\"]]\n",
        "print(compar[compar[\"version\"].isin([60, 85])].sort_values(\"f1_score\", ascending = False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a3cd40f-1cdb-4bc0-8a81-4972e278e1fb",
        "id": "NOhVXVkLTNqo"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    version  accuracy  f1_score  precision    recall  model_type\n",
            "3        85  0.814490  0.814199   0.816566  0.814534  Sequential\n",
            "12       60  0.792536  0.792094   0.795156  0.792587  Sequential\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Introducing more layers has improved f1 score from 0.79 to 0.81.\n",
        "\n",
        "There are now 3 LSTM layers in the model, the first two with 50 neurons and dropout rate of 0.2 and the final layer with 80 and a dropout rate of 0.3. Model #60 in comparison had 2 LSTM layers with 100 neurons each, the first with a dropout rate of 0.2 and the second with a dropout rate of 0.3. This model is also trained for 10 epochs instead of the original 5."
      ],
      "metadata": {
        "id": "StEBYXnNWZ5p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4.b. Model #86\n",
        "Retrain Model #85 with max_len = 100"
      ],
      "metadata": {
        "id": "SBYPAmqxUtW9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4812bcf3-7f9c-4a33-b82e-fb4fc67c1a6b",
        "id": "rMyc_wZpUQHY"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6920, 100)\n",
            "(1821, 100)\n"
          ]
        }
      ],
      "source": [
        "# This preprocessor function makes use of the tf.keras tokenizer\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "# Build vocabulary from training text data\n",
        "tokenizer = Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "# preprocessor tokenizes words and makes sure all documents have the same length\n",
        "def preprocessor(data, maxlen=100, max_words=10000):\n",
        "\n",
        "    sequences = tokenizer.texts_to_sequences(data)\n",
        "\n",
        "    word_index = tokenizer.word_index\n",
        "    X = pad_sequences(sequences, maxlen=maxlen)\n",
        "\n",
        "    return X\n",
        "\n",
        "print(preprocessor(X_train).shape)\n",
        "print(preprocessor(X_test).shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import aimodelshare as ai\n",
        "ai.export_preprocessor(preprocessor,\"\") "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "874dae35-3e76-411d-b8b8-8adb17a7c533",
        "id": "7PaR_nY5UQHY"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your preprocessor is now saved to 'preprocessor.zip'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Flatten\n",
        "max_len = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(10000, 16, input_length=max_len))\n",
        "model.add(LSTM(50, return_sequences=True, dropout=0.2))\n",
        "model.add(LSTM(50, return_sequences=True, dropout=0.2))\n",
        "model.add(LSTM(80, dropout=0.3))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vx1qeKPaXAID",
        "outputId": "4f7c7168-b511-4b05-a3f1-e80003a2fe04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_20 (Embedding)    (None, 100, 16)           160000    \n",
            "                                                                 \n",
            " lstm_35 (LSTM)              (None, 100, 50)           13400     \n",
            "                                                                 \n",
            " lstm_36 (LSTM)              (None, 100, 50)           20200     \n",
            "                                                                 \n",
            " lstm_37 (LSTM)              (None, 80)                41920     \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 80)                0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 2)                 162       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 235,682\n",
            "Trainable params: 235,682\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "history = model.fit(preprocessor(X_train), y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBJlCrvFXG2U",
        "outputId": "9d3a8d5f-183c-479d-93f0-c802dbe0c578"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "173/173 [==============================] - 56s 275ms/step - loss: 0.6495 - acc: 0.6339 - val_loss: 0.7335 - val_acc: 0.6062\n",
            "Epoch 2/10\n",
            "173/173 [==============================] - 50s 288ms/step - loss: 0.4858 - acc: 0.7711 - val_loss: 0.6673 - val_acc: 0.6431\n",
            "Epoch 3/10\n",
            "173/173 [==============================] - 48s 275ms/step - loss: 0.3638 - acc: 0.8387 - val_loss: 0.6045 - val_acc: 0.7247\n",
            "Epoch 4/10\n",
            "173/173 [==============================] - 49s 281ms/step - loss: 0.3377 - acc: 0.8696 - val_loss: 4.0732 - val_acc: 0.1488\n",
            "Epoch 5/10\n",
            "173/173 [==============================] - 49s 283ms/step - loss: 0.2696 - acc: 0.8941 - val_loss: 0.6206 - val_acc: 0.7312\n",
            "Epoch 6/10\n",
            "173/173 [==============================] - 47s 273ms/step - loss: 0.2242 - acc: 0.9099 - val_loss: 0.5288 - val_acc: 0.7601\n",
            "Epoch 7/10\n",
            "173/173 [==============================] - 50s 288ms/step - loss: 0.1888 - acc: 0.9230 - val_loss: 0.5673 - val_acc: 0.7782\n",
            "Epoch 8/10\n",
            "173/173 [==============================] - 47s 274ms/step - loss: 0.1700 - acc: 0.9306 - val_loss: 0.5501 - val_acc: 0.7724\n",
            "Epoch 9/10\n",
            "173/173 [==============================] - 50s 288ms/step - loss: 0.1567 - acc: 0.9375 - val_loss: 0.6205 - val_acc: 0.7630\n",
            "Epoch 10/10\n",
            "173/173 [==============================] - 49s 282ms/step - loss: 0.1391 - acc: 0.9418 - val_loss: 0.6530 - val_acc: 0.7659\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = mycompetition.get_leaderboard()\n",
        "compar = data[[\"version\", \"accuracy\", \"f1_score\", \"precision\", \"recall\", \"model_type\"]]\n",
        "print(compar[compar[\"version\"].isin([60, 85, 86])].sort_values(\"f1_score\", ascending = False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEYJ-o_OZI_r",
        "outputId": "88d5fe81-af66-462c-dd49-19ce55264524"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    version  accuracy  f1_score  precision    recall  model_type\n",
            "3        85  0.814490  0.814199   0.816566  0.814534  Sequential\n",
            "7        86  0.803513  0.802136   0.812417  0.803605  Sequential\n",
            "14       60  0.792536  0.792094   0.795156  0.792587  Sequential\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Greater max_len performances is actually weaker than max_len 40 as default preprocessing and the same exact model architecture. 0.802 f1_score vs. 0.814. Still performs better than model #60."
      ],
      "metadata": {
        "id": "jzmmgPsVbpC5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4.c. Model #97\n",
        "Bidirectional LSTM"
      ],
      "metadata": {
        "id": "5nwkds4GUvSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Embedding, Bidirectional\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Flatten\n",
        "maxlen = 40\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(10000, 16, input_length=maxlen))\n",
        "model.add(Bidirectional(LSTM(50, return_sequences = True, dropout = 0.2)))\n",
        "model.add(LSTM(50, dropout = 0.3))\n",
        "model.add(Dense(2, activation='softmax'))"
      ],
      "metadata": {
        "id": "ax3xjfhGTYFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "history = model.fit(preprocessor(X_train), y_train,\n",
        "                    epochs=5,\n",
        "                    batch_size=100,\n",
        "                    validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAWXqv6mWJJD",
        "outputId": "5b117f52-fdd2-4d3e-8c50-3598cf67ee93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "56/56 [==============================] - 24s 257ms/step - loss: 0.6604 - acc: 0.6142 - val_loss: 1.8926 - val_acc: 0.1936\n",
            "Epoch 2/5\n",
            "56/56 [==============================] - 8s 151ms/step - loss: 0.5005 - acc: 0.7697 - val_loss: 0.4933 - val_acc: 0.8071\n",
            "Epoch 3/5\n",
            "56/56 [==============================] - 12s 220ms/step - loss: 0.3556 - acc: 0.8475 - val_loss: 0.6410 - val_acc: 0.6799\n",
            "Epoch 4/5\n",
            "56/56 [==============================] - 9s 169ms/step - loss: 0.2738 - acc: 0.8940 - val_loss: 0.5301 - val_acc: 0.7803\n",
            "Epoch 5/5\n",
            "56/56 [==============================] - 12s 209ms/step - loss: 0.2121 - acc: 0.9198 - val_loss: 0.4735 - val_acc: 0.7760\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = mycompetition.get_leaderboard()\n",
        "compar = data[[\"version\", \"accuracy\", \"f1_score\", \"precision\", \"recall\", \"model_type\"]]\n",
        "print(compar[compar[\"version\"].isin([60, 85, 86, 97])].sort_values(\"f1_score\", ascending = False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkJR6Z5IYeqN",
        "outputId": "c0f206b7-a6d3-4e10-c01c-28b1ca7a2358"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    version  accuracy  f1_score  precision    recall  model_type\n",
            "3        85  0.814490  0.814199   0.816566  0.814534  Sequential\n",
            "4        97  0.811196  0.810978   0.812730  0.811235  Sequential\n",
            "8        86  0.803513  0.802136   0.812417  0.803605  Sequential\n",
            "16       60  0.792536  0.792094   0.795156  0.792587  Sequential\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This bidirectional layer model is the second top performing model with a f1 score of 0.811, only just behind #85 at 0.814. \n",
        "\n",
        "This model has 1 embedding layer with 10000 inputs and 16 outputs, 1 bidirectional LSTM layer with 50 neurons, and dropout of 0.2, and a regular LSTM layer with 50 neurons and dropout of 0.3. The dropout layers were introduced to prevent overfitting. "
      ],
      "metadata": {
        "id": "aATnUDldkzNK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Discuss results\n",
        "Discuss which models you tried and which models performed better and point out relevant hyper-parameter values for successful models."
      ],
      "metadata": {
        "id": "W_X24hwBUoof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = mycompetition.get_leaderboard()\n",
        "compar = data[[\"version\", \"accuracy\", \"f1_score\", \"precision\", \"recall\", \"model_type\"]]\n",
        "print(compar[compar[\"version\"].isin([60, 85, 86, 97, 61, 84])].sort_values(\"f1_score\", ascending = False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnPayxZdnYJp",
        "outputId": "5fa6ca37-013b-43f1-f818-c1e8092cbd31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    version  accuracy  f1_score  precision    recall  model_type\n",
            "3        85  0.814490  0.814199   0.816566  0.814534  Sequential\n",
            "4        97  0.811196  0.810978   0.812730  0.811235  Sequential\n",
            "8        86  0.803513  0.802136   0.812417  0.803605  Sequential\n",
            "16       60  0.792536  0.792094   0.795156  0.792587  Sequential\n",
            "18       61  0.788145  0.786414   0.798021  0.788245  Sequential\n",
            "69       84  0.678375  0.675876   0.684226  0.678473  Sequential\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Weaker Performing Models:** Of the 6 models I created, the three that performed the worst used glove embedding + transfer learning (#84), and embedding layers + conv1D layers (#61). Of my initial models, #60 was the best performer with an f1 score of 0.79. This model consists of 1 embedding layer with 10,000 input dimensions and 16 output dimensions, and 2 LSTM layers, each with 100 neurons. The first LSTM layer has a dropout rate of 0.2 and the secon has a dropout rate of 0.3. The model is flattened before the dense layer.This layer used the provided preprocessing technique that limits reviews to 40 words only. After training for 5 epochs in batches of 32, it rendered a f1_score of 0.792.\n",
        "\n",
        "I then improved upon model #60 in part 4 and produced 3 new models:\n",
        "\n",
        "**Best Performing Model: Model #85:** Model #85 is very similar to model #60 but more complex. This mdoel has 3 LSTM layers instead of 2 as in #60. The first two have 50 neurons and a dropout of 0.2 and the third layer has 80 neurons with dropout of 0.3. This model is also trained for 10 epochs instead of the original 5. This improved performance from 0.792 to 0.814.\n",
        "\n",
        "Model #97 and #86 were also from part 4 of the assignment, and aimed to improve upon the performance of model #60. \n",
        "\n",
        "**Second Best Performing Model: Model #97:** This model rendered a f1-score of 0.813 which is very similar to the performance of #85 at 0.814. In this model I experimented with bidirectional LSTM layers. This model has 1 embedding layer with 10000 inputs and 16 outputs, 1 bidirectional LSTM layer with 50 neurons, and dropout of 0.2, and a regular LSTM layer with 50 neurons and dropout of 0.3. The dropout layers were introduced to prevent overfitting.  \n",
        "\n",
        "In model #86 I experimented with different max lengths of the input text. Here, I changed the preprocessing of the text to a max length of 100 instead of 40. I used the same arhictecture as model #85 and found that this actually decreased performance. \n",
        "\n"
      ],
      "metadata": {
        "id": "OBjwZ54onmMR"
      }
    }
  ]
}